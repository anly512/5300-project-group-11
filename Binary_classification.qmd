---
title: "Project"
author: Michael Xie
format:
  html:
    page-layout: full
    code-fold: false
    code-copy: true
    code-tools: true
    code-overflow: wrap
embed-resources: true
fig-cap-location: bottom
---

```{r}
# Loading necessary libraries
library(readr)
library(dplyr)
library(caret)
library(ggplot2)
library(pROC)
library(MASS)  # For LDA and QDA
library(glmnet) # For Lasso and Ridge Regression
library(GGally) # For ggpairs

# Set seed for reproducibility
set.seed(123)

# Load the dataset
data <- read_csv("OnlineRetail.csv")

# Data preprocessing
# Convert InvoiceDate to POSIXct Date type if not already, and extract Date features
data$InvoiceDate <- as.POSIXct(data$InvoiceDate, format="%Y-%m-%d %H:%M:%S")
data$InvoiceDay <- as.Date(data$InvoiceDate)

# Removing the InvoiceDate column using base R
data <- data[, !names(data) %in% c("InvoiceDate")]

# Removing rows with NA values
data <- na.omit(data)

# Feature Engineering
# Adding new features like price per unit
data$TotalPrice <- data$Quantity * data$UnitPrice

# Aggregating data at the CustomerID level
agg_data <- data %>%
  group_by(CustomerID) %>%
  summarise(TotalSpend = sum(TotalPrice),
            Frequency = n_distinct(InvoiceNo),
            Recency = as.numeric(difftime(max(InvoiceDay), min(InvoiceDay), units = "days"))) %>%
  ungroup() %>% 
  na.omit()

# Create a binary outcome variable based on TotalSpend
agg_data$HighSpender <- ifelse(agg_data$TotalSpend > median(agg_data$TotalSpend), 1, 0)

# Scaling the features, but not the binary outcome or CustomerID
preProcValues <- preProcess(agg_data[, c("TotalSpend", "Frequency", "Recency")], method = c("center", "scale"))
scaled_data <- predict(preProcValues, agg_data[, c("TotalSpend", "Frequency", "Recency")])

# PCA for feature reduction on scaled data
pca <- prcomp(scaled_data)
pca_data <- data.frame(pca$x)

# Combining PCA data with the HighSpender binary outcome and CustomerID
pca_data <- cbind(pca_data, HighSpender = agg_data$HighSpender, CustomerID = agg_data$CustomerID)

# Train-Test Split
set.seed(123)
trainIndex <- createDataPartition(pca_data$HighSpender, p = .8, 
                                  list = FALSE, 
                                  times = 1)
train_data <- pca_data[trainIndex, ]
test_data <- pca_data[-trainIndex, ]

```


```{r}
# Models

# LDA Model
lda_fit <- lda(HighSpender ~ . - CustomerID, data=train_data)
summary(lda_fit)

# QDA Model
qda_fit <- qda(HighSpender ~ . - CustomerID, data=train_data)
summary(qda_fit)

# For Lasso and Ridge, we will use glmnet which requires matrix inputs and does not accept a data frame directly.
# Extract the matrix of predictor variables and the vector of outcomes
X_train <- as.matrix(train_data[, setdiff(names(train_data), c("HighSpender", "CustomerID"))])
y_train <- train_data$HighSpender

# Lasso and Ridge Regression for Logistic Regression
set.seed(123)
model_lasso <- glmnet(X_train, y_train, alpha = 1, family = "binomial")
model_ridge <- glmnet(X_train, y_train, alpha = 0, family = "binomial")

# Cross-validation for Lasso and Ridge
cv_lasso <- cv.glmnet(X_train, y_train, alpha = 1)
cv_ridge <- cv.glmnet(X_train, y_train, alpha = 0)

# Plot the CV error
plot(cv_lasso)
plot(cv_ridge)

# Now let's get the predictions for the test data
X_test <- as.matrix(test_data[, setdiff(names(test_data), c("HighSpender", "CustomerID"))])
y_test <- test_data$HighSpender

# Model Predictions
predictions_lda <- predict(lda_fit, newdata=test_data)$posterior[,2]
predictions_qda <- predict(qda_fit, newdata=test_data)$posterior[,2]
predictions_lasso <- predict(model_lasso, newx=X_test, s=cv_lasso$lambda.min, type="response")
predictions_ridge <- predict(model_ridge, newx=X_test, s=cv_ridge$lambda.min, type="response")

roc_lda <- roc(y_test, predictions_lda)
roc_qda <- roc(y_test, predictions_qda)
roc_lasso <- roc(y_test, predictions_lasso)
roc_ridge <- roc(y_test, predictions_ridge)

# Summarize ROC results
print(summary(roc_lda))
print(summary(roc_qda))
print(summary(roc_lasso))
print(summary(roc_ridge))
```

```{r}
# Convert probabilities to binary classification based on a threshold (e.g., 0.5)
threshold <- 0.5
pred_lda_binary <- ifelse(predictions_lda > threshold, 1, 0)
pred_qda_binary <- ifelse(predictions_qda > threshold, 1, 0)
pred_lasso_binary <- ifelse(predictions_lasso > threshold, 1, 0)
pred_ridge_binary <- ifelse(predictions_ridge > threshold, 1, 0)

# Confusion Matrices
confusion_lda <- confusionMatrix(factor(pred_lda_binary, levels=c(0, 1)), factor(y_test, levels=c(0, 1)))
confusion_qda <- confusionMatrix(factor(pred_qda_binary, levels=c(0, 1)), factor(y_test, levels=c(0, 1)))
confusion_lasso <- confusionMatrix(factor(pred_lasso_binary, levels=c(0, 1)), factor(y_test, levels=c(0, 1)))
confusion_ridge <- confusionMatrix(factor(pred_ridge_binary, levels=c(0, 1)), factor(y_test, levels=c(0, 1)))

# Print Confusion Matrices

print("Confusion Matrix for LDA:")
print(confusion_lda)

print("Confusion Matrix for QDA:")
print(confusion_qda)

print("Confusion Matrix for LASSO:")
print(confusion_lasso)

print("Confusion Matrix for RIDGE:")
print(confusion_ridge)
```

```{r}
# Convert the roc objects to data frames
roc_df_lda <- data.frame(
  TPR = roc_lda$sensitivities,
  FPR = 1 - roc_lda$specificities,
  Model = 'LDA'
)

roc_df_qda <- data.frame(
  TPR = roc_qda$sensitivities,
  FPR = 1 - roc_qda$specificities,
  Model = 'QDA'
)

roc_df_lasso <- data.frame(
  TPR = roc_lasso$sensitivities,
  FPR = 1 - roc_lasso$specificities,
  Model = 'Lasso'
)

roc_df_ridge <- data.frame(
  TPR = roc_ridge$sensitivities,
  FPR = 1 - roc_ridge$specificities,
  Model = 'Ridge'
)

# Combine all data frames into one for plotting
roc_data <- rbind(roc_df_lda, roc_df_qda, roc_df_lasso, roc_df_ridge)
```


```{r}
ggplot(roc_data, aes(x = FPR, y = TPR, color = Model)) +
  geom_line() +
  geom_abline(linetype = "dashed", color = "gray", slope = 1, intercept = 0) +
  labs(
    title = "ROC Curves",
    x = "False Positive Rate (1 - Specificity)",
    y = "True Positive Rate (Sensitivity)",
    color = "Model"
  ) +
  scale_color_manual(values = c("LDA" = "blue", "QDA" = "green", "Lasso" = "purple", "Ridge" = "orange")) +
  theme_minimal() +
  theme(legend.position = "bottom")
```
```{r}
ggplot(agg_data, aes(x=factor(HighSpender), y=TotalSpend, fill=factor(HighSpender))) +
  geom_bar(stat="summary", fun="mean") +
  scale_fill_manual(values=c("#FF9999", "#9999FF")) +
  labs(x="High Spender (1 = Yes, 0 = No)", y="Average Total Spend", fill="High Spender") +
  ggtitle("Average Total Spend by High Spender Status") +
  theme_minimal()
```

```{r}
ggplot(agg_data, aes(x=factor(HighSpender), y=Recency, fill=factor(HighSpender))) +
  geom_bar(stat="summary", fun="mean") +
  scale_fill_manual(values=c("#FF9999", "#9999FF")) +
  labs(x="High Spender (1 = Yes, 0 = No)", y="Average Recency", fill="High Spender") +
  ggtitle("Average Recency by High Spender Status") +
  theme_minimal()
```

```{r}
# Create function to plot confusion matrix
plot_confusion_matrix <- function(confusion_matrix, title) {
  confusion_matrix_df <- as.data.frame(as.table(confusion_matrix$table))
  names(confusion_matrix_df) <- c("Predicted", "Actual", "Count")
  
  ggplot(data = confusion_matrix_df, aes(x = Actual, y = Predicted, fill = Count)) +
    geom_tile(color = "white") +
    geom_text(aes(label = Count), vjust = 1) +
    scale_fill_gradient(low = "white", high = "steelblue", na.value = "grey50") +
    labs(title = title,
         x = "Actual",
         y = "Predicted") +
    theme_minimal() +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))
}

# Plot confusion matrices for each model
plot_confusion_matrix(confusion_lda, "Confusion Matrix - LDA")
plot_confusion_matrix(confusion_qda, "Confusion Matrix - QDA")
plot_confusion_matrix(confusion_lasso, "Confusion Matrix - Lasso")
plot_confusion_matrix(confusion_ridge, "Confusion Matrix - Ridge")
```

```{r}
ggplot(roc_data, aes(x = FPR, y = TPR, color = Model)) +
  geom_line(size = 1.2) +  # Increase line thickness
  geom_abline(linetype = "dashed", color = "gray", size = 1) +  # Adjust dashed line
  labs(
    title = "ROC Curves",
    x = "False Positive Rate (1 - Specificity)",
    y = "True Positive Rate (Sensitivity)",
    color = "Model"
  ) +
  scale_color_manual(values = c("LDA" = "blue", "QDA" = "green", "Lasso" = "purple", "Ridge" = "orange")) +
  theme_minimal(base_size = 14) +  # Increase base font size
  theme(legend.position = "bottom",  # Move legend to bottom
        axis.title = element_text(size = 16),  # Increase axis title font size
        axis.text = element_text(size = 14),  # Increase axis text font size
        legend.title = element_text(size = 14),  # Increase legend title font size
        legend.text = element_text(size = 14))  # Increase legend text font size
```











